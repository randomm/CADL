# Glossary

This glossary tries to index the terms used throughout the course.  This is a work in progress and contributions are welcomed.

# Table of Contents

<!-- MarkdownTOC autolink=true autohref=ture -->

- [1x1 Convolutions](#1x1-convolutions)
- [1-D Gaussian Kernel](#1-d-gaussian-kernel)
- [2-D Gaussian Kernel](#2-d-gaussian-kernel)
- [Activation Function](#activation-function)
- [Accuracy](#accuracy)
- [Adversarial Network](#adversarial-network)
- [Adversarial Training](#adversarial-training)
- [ANN](#ann)
- [Artificial Intelligence](#artificial-intelligence)
- [Autoencoders](#autoencoders)
- [Back-prop](#back-prop)
- [Back-propagation](#back-propagation)
- [Back-propagation Through Time](#back-propagation-through-time)
- [Batch Dimension](#batch-dimension)
- [Batch Normalization](#batch-normalization)
- [Batches](#batches)
- [Bias](#bias)
- [Blur](#blur)
- [Celeb Dataset](#celeb-dataset)
- [Char-RNN](#char-rnn)
- [Character Language Model](#character-language-model)
- [Checkpoint](#checkpoint)
- [Classification](#classification)
- [Classification Network](#classification-network)
- [Clip](#clip)
- [Complex Cell](#complex-cell)
- [Computational Graph](#computational-graph)
- [Computer Vision](#computer-vision)
- [Conditional Probability](#conditional-probability)
- [Content Features](#content-features)
- [Content Loss](#content-loss)
- [Context Managers](#context-managers)
- [Convolution](#convolution)
- [Convolutional Autoencoder](#convolutional-autoencoder)
- [Convolutional Networks](#convolutional-networks)
- [Convolve](#convolve)
- [Covariance](#covariance)
- [Covariance Matrix](#covariance-matrix)
- [Cost](#cost)
- [Cross Entropy](#cross-entropy)
- [Cross Validation](#cross-validation)
- [Dataset](#dataset)
- [Dataset Augmentation](#dataset-augmentation)
- [DCGAN](#dcgan)
- [Decoder](#decoder)
- [Deep Convolutional Networks](#deep-convolutional-networks)
- [Deep Dream](#deep-dream)
- [Deep Dreaming](#deep-dreaming)
- [Deep Learning vs. Machine Learning](#deep-learning-vs-machine-learning)
- [Denoising Autoencoder](#denoising-autoencoder)
- [Deprocessing](#deprocessing)
- [Deviation](#deviation)
- [Discriminator](#discriminator)
- [Distributed Representation](#distributed-representation)
- [Dot Product](#dot-product)
- [DRAW](#draw)
- [Dropout](#dropout)
- [Early Stopping](#early-stopping)
- [Embedding](#embedding)
- [Encoder](#encoder)
- [Epoch](#epoch)
- [Equilibrium](#equilibrium)
- [Error](#error)
- [Example](#example)
- [Feed-forward Neural Network](#feed-forward-neural-network)
- [Filter](#filter)
- [Fine Tuning](#fine-tuning)
- [Forward Propagation](#forward-propagation)
- [Fully Connected](#fully-connected)
- [Gabor](#gabor)
- [GAN](#gan)
- [Gaussian](#gaussian)
- [Gaussian Kernel](#gaussian-kernel)
- [Generalized Matrix Multiplication](#generalized-matrix-multiplication)
- [Generative Adversarial Networks](#generative-adversarial-networks)
- [Generator](#generator)
- [Gradient](#gradient)
- [Gradient Clipping](#gradient-clipping)
- [Gradient Descent](#gradient-descent)
- [Graph Definition](#graph-definition)
- [Graphs](#graphs)
- [GRU](#gru)
- [Guided Hallucinations](#guided-hallucinations)
- [Hidden Layer](#hidden-layer)
- [Histogram Equalization](#histogram-equalization)
- [Histograms](#histograms)
- [Hyperparameters](#hyperparameters)
- [Image Inpainting](#image-inpainting)
- [Image Labels](#image-labels)
- [Inception Module](#inception-module)
- [Inception Network](#inception-network)
- [Inference](#inference)
- [Input's Representation](#inputs-representation)
- [Invariances](#invariances)
- [Kernel](#kernel)
- [LAPGAN](#lapgan)
- [Laplacian Pyramid](#laplacian-pyramid)
- [Latent Encoding](#latent-encoding)
- [Latent Feature Arithmetic](#latent-feature-arithmetic)
- [Latent-Space](#latent-space)
- [Layer](#layer)
- [Learning From Data](#learning-from-data)
- [Learning Rate](#learning-rate)
- [Linear Regression](#linear-regression)
- [Loading a Pretrained Network](#loading-a-pretrained-network)
- [Local Minima/Optima](#local-minimaoptima)
- [Long Short Term Memory](#long-short-term-memory)
- [Loss](#loss)
- [LSTM](#lstm)
- [Machine Learning](#machine-learning)
- [Manifold](#manifold)
- [Matrix](#matrix)
- [Matrix Inverse](#matrix-inverse)
- [Matrix Multiplication](#matrix-multiplication)
- [Max Pooling](#max-pooling)
- [Mean](#mean)
- [Mini Batch](#mini-batch)
- [Mini Batch Gradient Descent](#mini-batch-gradient-descent)
- [MNIST](#mnist)
- [Models](#models)
- [Network](#network)
- [Network Labels](#network-labels)
- [Neural Network](#neural-network)
- [Nonlinearities](#nonlinearities)
- [Norm](#norm)
- [Normalization](#normalization)
- [Objective](#objective)
- [One-Hot Encoding](#one-hot-encoding)
- [Operations](#operations)
- [Optimization](#optimization)
- [Optimizers](#optimizers)
- [Over vs. Underfitting](#over-vs-underfitting)
- [Preprocess](#preprocess)
- [Preprocessing](#preprocessing)
- [Pretrained Networks](#pretrained-networks)
- [Priming](#priming)
- [Probabilistic Sampling](#probabilistic-sampling)
- [Protobuf](#protobuf)
- [Rectified Linear Unit](#rectified-linear-unit)
- [Recurrent Neural Networks](#recurrent-neural-networks)
- [Regression](#regression)
- [Reinforcement Learning](#reinforcement-learning)
- [ReLu](#relu)
- [RNN](#rnn)
- [Scalar](#scalar)
- [Sessions](#sessions)
- [Sigmoid](#sigmoid)
- [Simple Cell](#simple-cell)
- [Softmax](#softmax)
- [Softmax Layer](#softmax-layer)
- [Sparse](#sparse)
- [Standard Deviation](#standard-deviation)
- [Stochastic](#stochastic)
- [Stochastic Mini Batch Gradient Descent](#stochastic-mini-batch-gradient-descent)
- [Style Features](#style-features)
- [Style Loss](#style-loss)
- [Style Net](#style-net)
- [Supervised Learning](#supervised-learning)
- [TanH](#tanh)
- [Temperature](#temperature)
- [Tensor](#tensor)
- [Tensor Shapes](#tensor-shapes)
- [Tensorboard](#tensorboard)
- [Tensorflow Basics](#tensorflow-basics)
- [Tensors](#tensors)
- [Testing](#testing)
- [Total Variation Loss](#total-variation-loss)
- [Training](#training)
- [Training Error](#training-error)
- [Training Parameters](#training-parameters)
- [Training vs. Testing](#training-vs-testing)
- [Transpose](#transpose)
- [Unsupervised Learning](#unsupervised-learning)
- [Unsupervised vs. Supervised Learning](#unsupervised-vs-supervised-learning)
- [VAEGAN](#vaegan)
- [Validation](#validation)
- [Validation Error](#validation-error)
- [Variable](#variable)
- [Variance](#variance)
- [Variational Auto-Encoding Generative Adversarial Network](#variational-auto-encoding-generative-adversarial-network)
- [Variational Autoencoders](#variational-autoencoders)
- [Variational Layer](#variational-layer)
- [Vector](#vector)
- [VGG Network](#vgg-network)

<!-- /MarkdownTOC -->


<a name="1x1-convolutions"></a>
# 1x1 Convolutions

This defines an operation where the height and width of the kernel of a [convolution](#convolution) operation are set to 1.  This is useful because the depth dimension of the convolution operation can still be used to reduce the dimensionality (or increase it).  So for instance, if we have batch number of 100 x 100 images w/ 3 color channels, we can define a 1x1 convolution which reduces the 3 color channels to just 1 channel of information.  This is often applied before a much more expensive operation to reduce the number of overall parameters.

<a name="1-d-gaussian-kernel"></a>
# 1-D Gaussian Kernel

The image below depicts a 1-D Gaussian Kernel:

![imgs/1d-gaussian.png](imgs/1d-gaussian.png)

In Tensorflow, the 1-D Gaussian can be computed by specifying the two parameters, `mean` and the standard deviation, which is commonly denoted by the name `sigma`.

```python
mean = 0.0
sigma = 1.0
z = (tf.exp(tf.neg(tf.pow(x - mean, 2.0) /
                   (2.0 * tf.pow(sigma, 2.0)))) *
     (1.0 / (sigma * tf.sqrt(2.0 * 3.1415))))
```

<a name="2-d-gaussian-kernel"></a>
# 2-D Gaussian Kernel

Like the 1-D Gaussian Kernel, the 2-D Gaussian Kernel has its peak in the middle and reduces in value exponentially as you move outside the center.  When the 1-D Gaussian is [matrix multiplied](#matrix-multiplication) with the [matrix transpose](#matrix-transpose) of itself, the 1-D Gaussian can be depicted in 2-dimensions as such:

![imgs/2d-gaussian.png](imgs/2d-gaussian.png)

Following from the definition of the 1-D Gaussian Kernel, the 2-D Gaussian Kernel can be computed in Tensorflow as such:

```python
# Let's store the number of values in our Gaussian curve.
ksize = z.get_shape().as_list()[0]

# Let's multiply the two to get a 2d gaussian
z_2d = tf.matmul(tf.reshape(z, [ksize, 1]), tf.reshape(z, [1, ksize]))
```

<a name="activation-function"></a>
# Activation Function

The activation function, also known as the non-linearity, describes the non-linear operation in a Neural Network.  Neural Networks gain the power to describe very complex functions by performing series of linear + nonlinear operations.  These two series of operations, linear followed by a nonlinear operation, are typically grouped together in a single layer, and a neural network is composed of many layers.  Typical activation functions include the [sigmoid](#sigmoid), [TanH](#tanh), or [ReLu](#relu), as shown below:

![imgs/activation.png](imgs/activation.png)

This graph depicts three activation functions.  Any value on the x, horizontal axis, is transformed "nonlinearly" as the value on the y, vertical axis.

<a name="accuracy"></a>
# Accuracy

In [classification](#classification) tasks, the accuracy describes how well a network does at predicting the correct class.

In Tensorflow, we might calculate it like so, assuming we have the true output of the network in `Y`, and a predicted output in `Y_pred`:

```python
predicted_y = tf.argmax(Y_pred, 1)
actual_y = tf.argmax(Y, 1)

# We can then measure the accuracy by seeing whenever these are equal.
correct_prediction = tf.equal(predicted_y, actual_y)
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
```

<a name="adversarial-network"></a>
# Adversarial Network

This network described by [1] is composed of two networks, a [Generator](#generator) and a [Discriminator](#discriminator).  Together, they are known as the Generative Adversarial Network.  The basic idea is the generator is trying to create things which look like the training data. So for images, more images that look like the training data. The discriminator has to guess whether what its given is a real training example. Or whether its the output of the generator. By training one after another, you ensure neither are ever too strong, but both grow stronger together. The discriminator is also learning a distance function! This is pretty cool because we no longer need to measure pixel-based distance, but we learn the distance function entirely!

The Generative Adversarial Network, or GAN, for short, are in a way, very similar to autoencoders. Or at least the implementation of it is. The discriminator is a lot like the encoder part of the network, except it reduces the input down to a single value, yes or no, 0 or 1, denoting yes its a true training example, or no, it's a generated one.

And the generator network is exactly like the decoder of the autoencoder. Except, there is nothing feeding into this inner layer. It is just on its own. From whatever vector of hidden values it starts off with, it will generate a new example meant to look just like the training data. One pitfall of this model is there is no explicit encoding of an input. Meaning, you can't take an input and find what would possibly generate it. However, there are recent extensions to this model which make it more like the autoencoder framework, allowing it to do this, such as the [VAEGAN](#vaegan) model.

![imgs/gan-1.png](imgs/gan-1.png)

[1]. Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … Bengio, Y. (2014). Generative Adversarial Networks, 1–9. Retrieved from http://arxiv.org/abs/1406.2661

<a name="adversarial-training"></a>
# Adversarial Training

This describes the process of training a network like the [Adversarial Network](#adversarial-network).  It is usually composed of two networks whose loss functions are to fool one another.  It is related to game theory in that there should be an equilibrium that allows both models to get stronger together.  If that 

<a name="ann"></a>
# ANN

<a name="artificial-intelligence"></a>
# Artificial Intelligence

<a name="autoencoders"></a>
# Autoencoders

An autoencoder describes a network which [encodes](#encoder) its input to some [latent encoding](#latent-encoding) layer of smaller dimensions, and then [decodes](#decoder) this [latent layer](#latent-layer) back to the original input space dimensions.  The purpose of such a network is usually to compress the information in a large dataset such that the inner most, or the layer just following the encoder, is capable of retaining as much of the information necessary to reconstitute the original dataset.  For instance, an image of 256 x 256 x 3 dimensions may be encoded to merely 2 values describing any image's latent encoding. The decoder is then capable of taking these 2 values and creating an image resembling the original image, depending on how well the network is trained/performs.

<a name="back-prop"></a>
# Back-prop

<a name="back-propagation"></a>
# Back-propagation

This describes the process of the backwards propagation of the training signal, or error, from a neural network, to each of the gradients in a network using the [chain rule of calculus](https://en.wikipedia.org/wiki/Chain_rule).  This process is used with an optimization technique such as Gradient Descent.

<a name="back-propagation-through-time"></a>
# Back-propagation Through Time


<a name="batch-dimension"></a>
# Batch Dimension

The "batch" dimension is often the first, but not necessarily the first, dimension of a [Tensor](#tensor).  For example, a 10 x 256 x 256 x 3 dimension Tensor has 10 images of 256 x 256 x 3 dimensions.  The batch dimensions indexes all the observations in a ["mini-batch"](#mini-batch), or a small subset of examples from a larger dataset.  This is used during [Mini Batch Gradient Descent](#mini-batch-gradient-descent) to train a network on the entire contents of a larger dataset.

<a name="batch-normalization"></a>
# Batch Normalization

Batch Normalization describes a technique for [regularization](#regularization) which effectively smooths the gradient updates during [back-propagation](#back-propagation).  It is suggested by the authors of the technique that it should be applied just before the [activation function](#activation-function) of a layer.

<a name="batches"></a>
# Batches

Batches describe the individual mini-batches in [mini batch gradient descent](#mini-batch-gradient-descent) used during [training](#training).

<a name="bias"></a>
# Bias

<a name="blur"></a>
# Blur

Blurring is a technique which effectively smooths a signal, reducing "high-frequencies", or sharp discontinuities in a signal.  It is often used a technique for [regularization](#regularization), for instance during [Deep Dream](#deep-dream) or [Style Net](#style-net), on the overall activations of a gradient or the final result.

<a name="celeb-dataset"></a>
# Celeb Dataset

Celeb Dataset describes a dataset of over 200,000 images of celebrity faces: http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html - a popular choice of dataset for image networks as it contains a version of the dataset which has been "frontally aligned", meaning a computer vision technique was used to find the faces in various photos and align and warp them so that it looks like the faces are looking straight into the camera.  This effectively reduces the overall [invariances](#invariances) in the dataset, making it a simpler dataset to learn.

<a name="char-rnn"></a>
# Char-RNN

<a name="character-language-model"></a>
# Character Language Model

<a name="checkpoint"></a>
# Checkpoint

<a name="classification"></a>
# Classification

<a name="classification-network"></a>
# Classification Network

<a name="clip"></a>
# Clip

<a name="complex-cell"></a>
# Complex Cell

<a name="computational-graph"></a>
# Computational Graph

<a name="computer-vision"></a>
# Computer Vision

<a name="conditional-probability"></a>
# Conditional Probability

<a name="content-features"></a>
# Content Features

<a name="content-loss"></a>
# Content Loss

<a name="context-managers"></a>
# Context Managers

<a name="convolution"></a>
# Convolution

<a name="convolutional-autoencoder"></a>
# Convolutional Autoencoder

<a name="convolutional-networks"></a>
# Convolutional Networks

<a name="convolve"></a>
# Convolve

<a name="covariance"></a>
# Covariance

<a name="covariance-matrix"></a>
# Covariance Matrix

<a name="cost"></a>
# Cost

<a name="cross-entropy"></a>
# Cross Entropy

<a name="cross-validation"></a>
# Cross Validation

<a name="dataset"></a>
# Dataset

<a name="dataset-augmentation"></a>
# Dataset Augmentation

<a name="dcgan"></a>
# DCGAN

<a name="decoder"></a>
# Decoder

<a name="deep-convolutional-networks"></a>
# Deep Convolutional Networks

<a name="deep-dream"></a>
# Deep Dream

<a name="deep-dreaming"></a>
# Deep Dreaming

<a name="deep-learning-vs-machine-learning"></a>
# Deep Learning vs. Machine Learning

Deep Learning is a type of Machine Learning algorithm that uses Neural Networks to learn. The type of learning is "Deep" because it is composed of many layers of Neural Networks.

<a name="denoising-autoencoder"></a>
# Denoising Autoencoder

<a name="deprocessing"></a>
# Deprocessing

<a name="deviation"></a>
# Deviation

<a name="discriminator"></a>
# Discriminator

<a name="distributed-representation"></a>
# Distributed Representation

<a name="dot-product"></a>
# Dot Product

<a name="draw"></a>
# DRAW

<a name="dropout"></a>
# Dropout

<a name="early-stopping"></a>
# Early Stopping

<a name="embedding"></a>
# Embedding

<a name="encoder"></a>
# Encoder

<a name="epoch"></a>
# Epoch

<a name="equilibrium"></a>
# Equilibrium

<a name="error"></a>
# Error

<a name="example"></a>
# Example

<a name="feed-forward-neural-network"></a>
# Feed-forward Neural Network

<a name="filter"></a>
# Filter

<a name="fine-tuning"></a>
# Fine Tuning

<a name="forward-propagation"></a>
# Forward Propagation

<a name="fully-connected"></a>
# Fully Connected

<a name="gabor"></a>
# Gabor

![imgs/gabor.png](imgs/gabor.png)

<a name="gan"></a>
# GAN

<a name="gaussian"></a>
# Gaussian

<a name="gaussian-kernel"></a>
# Gaussian Kernel

<a name="generalized-matrix-multiplication"></a>
# Generalized Matrix Multiplication

<a name="generative-adversarial-networks"></a>
# Generative Adversarial Networks

<a name="generator"></a>
# Generator

<a name="gradient"></a>
# Gradient

<a name="gradient-clipping"></a>
# Gradient Clipping

<a name="gradient-descent"></a>
# Gradient Descent

![imgs/gradient-descent.png](imgs/gradient-descent.png)

<a name="graph-definition"></a>
# Graph Definition

<a name="graphs"></a>
# Graphs

<a name="gru"></a>
# GRU

<a name="guided-hallucinations"></a>
# Guided Hallucinations

<a name="hidden-layer"></a>
# Hidden Layer

<a name="histogram-equalization"></a>
# Histogram Equalization

<a name="histograms"></a>
# Histograms

<a name="hyperparameters"></a>
# Hyperparameters

<a name="image-inpainting"></a>
# Image Inpainting

<a name="image-labels"></a>
# Image Labels

<a name="inception-module"></a>
# Inception Module

<a name="inception-network"></a>
# Inception Network

<a name="inference"></a>
# Inference

<a name="inputs-representation"></a>
# Input's Representation

<a name="invariances"></a>
# Invariances

We usually describe the factors which represent something "invariances". That just means we are trying not to vary based on some factor. We are invariant to it. For instance, an object could appear to one side of an image, or another. We call that translation invariance. Or it could be from one angle or another. That's called rotation invariance. Or it could be closer to the camera, or farther. and That would be scale invariance. There are plenty of other types of invariances, such as perspective or brightness or exposure in the case of photographic images.  Many researchers/scientists/philosophers will have other definitions of this term.

<a name="kernel"></a>
# Kernel

<a name="lapgan"></a>
# LAPGAN

<a name="laplacian-pyramid"></a>
# Laplacian Pyramid

<a name="latent-encoding"></a>
# Latent Encoding

<a name="latent-feature-arithmetic"></a>
# Latent Feature Arithmetic

<a name="latent-space"></a>
# Latent-Space

<a name="layer"></a>
# Layer

<a name="learning-from-data"></a>
# Learning From Data

<a name="learning-rate"></a>
# Learning Rate

![imgs/learning-rate.png](imgs/learning-rate.png)

<a name="linear-regression"></a>
# Linear Regression

<a name="loading-a-pretrained-network"></a>
# Loading a Pretrained Network

<a name="local-minimaoptima"></a>
# Local Minima/Optima

<a name="long-short-term-memory"></a>
# Long Short Term Memory

<a name="loss"></a>
# Loss

<a name="lstm"></a>
# LSTM

<a name="machine-learning"></a>
# Machine Learning

<a name="manifold"></a>
# Manifold

<a name="matrix"></a>
# Matrix

<a name="matrix-inverse"></a>
# Matrix Inverse

<a name="matrix-multiplication"></a>
# Matrix Multiplication

<a name="max-pooling"></a>
# Max Pooling

<a name="mean"></a>
# Mean

<a name="mini-batch"></a>
# Mini Batch

<a name="mini-batch-gradient-descent"></a>
# Mini Batch Gradient Descent

<a name="mnist"></a>
# MNIST

<a name="models"></a>
# Models

<a name="network"></a>
# Network

<a name="network-labels"></a>
# Network Labels

<a name="neural-network"></a>
# Neural Network

<a name="nonlinearities"></a>
# Nonlinearities

<a name="norm"></a>
# Norm

<a name="normalization"></a>
# Normalization

<a name="objective"></a>
# Objective

<a name="one-hot-encoding"></a>
# One-Hot Encoding

<a name="operations"></a>
# Operations

<a name="optimization"></a>
# Optimization

<a name="optimizers"></a>
# Optimizers

<a name="over-vs-underfitting"></a>
# Over vs. Underfitting

<a name="preprocess"></a>
# Preprocess

<a name="preprocessing"></a>
# Preprocessing

<a name="pretrained-networks"></a>
# Pretrained Networks

<a name="priming"></a>
# Priming

<a name="probabilistic-sampling"></a>
# Probabilistic Sampling

<a name="protobuf"></a>
# Protobuf

<a name="rectified-linear-unit"></a>
# Rectified Linear Unit

A common type of [Activation Function](#activation-function) which performs the nonlinear operation in Tensorflow as:

```python
tf.maximum(0, x)
```

It is linear except for a discontinuity at 0 and can effectively learn nonlinear patterns with less computation than a sigmoid or tanh function requires.  It can also lead to [sparse](#sparse) activations, meaning not all the weights in a network are active.

There are also many extensions to ReLus, such as Leaky ReLus, Parametric ReLus, and Noisy ReLus.

<a name="recurrent-neural-networks"></a>
# Recurrent Neural Networks

<a name="regression"></a>
# Regression

<a name="reinforcement-learning"></a>
# Reinforcement Learning

<a name="relu"></a>
# ReLu

Abbreviation of [Rectified Linear Unit](#rectified-linear-unit).

<a name="rnn"></a>
# RNN

<a name="scalar"></a>
# Scalar

<a name="sessions"></a>
# Sessions

<a name="sigmoid"></a>
# Sigmoid

<a name="simple-cell"></a>
# Simple Cell

<a name="softmax"></a>
# Softmax

<a name="softmax-layer"></a>
# Softmax Layer

<a name="sparse"></a>
# Sparse

<a name="standard-deviation"></a>
# Standard Deviation

<a name="stochastic"></a>
# Stochastic

<a name="stochastic-mini-batch-gradient-descent"></a>
# Stochastic Mini Batch Gradient Descent

<a name="style-features"></a>
# Style Features

<a name="style-loss"></a>
# Style Loss

<a name="style-net"></a>
# Style Net

<a name="supervised-learning"></a>
# Supervised Learning

<a name="tanh"></a>
# TanH

<a name="temperature"></a>
# Temperature

<a name="tensor"></a>
# Tensor

<a name="tensor-shapes"></a>
# Tensor Shapes

<a name="tensorboard"></a>
# Tensorboard

<a name="tensorflow-basics"></a>
# Tensorflow Basics

<a name="tensors"></a>
# Tensors

<a name="testing"></a>
# Testing

<a name="total-variation-loss"></a>
# Total Variation Loss

<a name="training"></a>
# Training

<a name="training-error"></a>
# Training Error

<a name="training-parameters"></a>
# Training Parameters

<a name="training-vs-testing"></a>
# Training vs. Testing

<a name="transpose"></a>
# Transpose

<a name="unsupervised-learning"></a>
# Unsupervised Learning

<a name="unsupervised-vs-supervised-learning"></a>
# Unsupervised vs. Supervised Learning

Machine learning research in deep networks performs one of two types of learning. You either have a lot of data and you want the computer to reason about it, maybe to encode the data using less data, and just explore what patterns there might be. That's useful for clustering data, reducing the dimensionality of the data, or even for generating new data. That's generally known as unsupervised learning. In the supervised case, you actually know what you want out of your data. You have something like a label or a class that is paired with every single piece of data.

<a name="vaegan"></a>
# VAEGAN

<a name="validation"></a>
# Validation

<a name="validation-error"></a>
# Validation Error

<a name="variable"></a>
# Variable

<a name="variance"></a>
# Variance

<a name="variational-auto-encoding-generative-adversarial-network"></a>
# Variational Auto-Encoding Generative Adversarial Network

<a name="variational-autoencoders"></a>
# Variational Autoencoders

<a name="variational-layer"></a>
# Variational Layer

<a name="vector"></a>
# Vector

<a name="vgg-network"></a>
# VGG Network

---

Thanks to Golan Levin for [suggesting the idea](https://twitter.com/golan/status/798619471199883264).
